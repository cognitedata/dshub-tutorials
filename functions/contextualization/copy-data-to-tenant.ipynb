{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy assets and time series from publicdata tenant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook copies all assets and time series (without data points) from publicdata. This can for instance be used to test contextualization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import json\n",
    "from cognite.client import CogniteClient\n",
    "from cognite.client.data_classes import Asset, TimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have downloaded all assets and time series to `publicdata.json` so you don't have to generate an API key to publicdata yourself. First we open the file and populate two variables `assets` and `time_series` before we replace them with native `Asset` and `TimeSeries` objects that the SDK wants as input. To preserve the asset hierarchy structure, we use the original internal id as `external_id`, and the `parent_id` as `parent_external_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1106 assets and 363 time series\n"
     ]
    }
   ],
   "source": [
    "with open(\"publicdata.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    assets = data[\"assets\"]\n",
    "    time_series = data[\"time_series\"]\n",
    "    print(f\"Found {len(assets)} assets and {len(time_series)} time series\")\n",
    "# Create Asset objects and TimeSeries objects. Use id's from existing source as external_id + parent_external_id to preserve asset hierarchy\n",
    "assets = [Asset(name = asset[\"name\"], description = asset.get(\"description\"), external_id = asset[\"id\"], parent_external_id = asset.get(\"parent_id\"), source=\"publicdata\") for asset in assets]\n",
    "time_series = [TimeSeries(name = ts[\"name\"], description = ts.get(\"description\"), metadata={\"source\": \"publicdata\"}) for ts in time_series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you put in the api key and tenant name to your tenant you want to copy the data to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = getpass()\n",
    "client = CogniteClient(\n",
    "    api_key=api_key, \n",
    "    project=\"functions-tutorial\",\n",
    "    client_name=\"DSHub\",\n",
    "    base_url=\"https://greenfield.cognitedata.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an asset hierarchy, we can in principle use the `client.assets.create_hierarchy` function, but we've encountered problems with it, so let's just do it the simple way by manually sorting assets depth by depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_by_id = {}\n",
    "for asset in assets:\n",
    "    assets_by_id[asset.external_id] = asset\n",
    "    \n",
    "def find_depth(asset_id, depth=0):\n",
    "    if asset_id in assets_by_id:\n",
    "        asset = assets_by_id[asset_id]\n",
    "        if asset.parent_external_id:\n",
    "            return find_depth(asset.parent_external_id, depth+1)\n",
    "        return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 assets for depth 0\n",
      "Creating 1 assets for depth 1\n",
      "Creating 1 assets for depth 2\n",
      "Creating 1 assets for depth 3\n",
      "Creating 3 assets for depth 4\n",
      "Creating 5 assets for depth 5\n",
      "Creating 48 assets for depth 6\n",
      "Creating 155 assets for depth 7\n",
      "Creating 303 assets for depth 8\n",
      "Creating 325 assets for depth 9\n",
      "Creating 194 assets for depth 10\n",
      "Creating 63 assets for depth 11\n",
      "Creating 6 assets for depth 12\n",
      "Done with 1106 assets. Creating time series ...\n",
      "Created 363 time_series\n"
     ]
    }
   ],
   "source": [
    "assets_by_depth = {}\n",
    "for asset in assets:\n",
    "    depth = find_depth(asset.external_id)\n",
    "    if not depth in assets_by_depth:\n",
    "        assets_by_depth[depth] = []\n",
    "    assets_by_depth[depth].append(asset)\n",
    "\n",
    "for depth in sorted(assets_by_depth.keys()):\n",
    "    print(f\"Creating {len(assets_by_depth[depth])} assets for depth {depth}\")\n",
    "    client.assets.create(assets_by_depth[depth])\n",
    "print(f\"Done with {len(assets)} assets. Creating time series ...\")\n",
    "\n",
    "client.time_series.create(time_series)\n",
    "print(f\"Created {len(time_series)} time_series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Matching with SDK-experimental demo\n",
    "\n",
    "This notebook uses a small dummy data set to demonstrate how to do entity matching using cognite-sdk-python-experimental.\n",
    "\n",
    "It aims at demonstrating most of the capabilities available, explain when the different parameter combinations are most suitable and explain (in some detail) what happens in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get access to CDF\n",
    "We assume you have some basic knowledge of CDF and the SDK. If not, please follow the 'lab' tutorials first.\n",
    "\n",
    "To do this tutorial you nee have access to a Cognite project / tenant, you can apply for one here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "We need to import some Python modules in order to interact with CDF. We will use the Python SDK with Experimental Extensions, which we below refer to as a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.client.exceptions import CogniteAPIError\n",
    "from cognite.experimental import CogniteClient # version: ~0.22.3\n",
    "from getpass import getpass\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a client\n",
    "\n",
    "To get access to your project, replace \"yourproject\" with your project name in the next cell. \n",
    "\n",
    "When you create the CogniteClient below, getpass will ask for your API key in an extra password field. Simply paste it in and press shift+enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'your-project'\n",
    "api_key = getpass(\"Please enter API key: \")\n",
    "client = CogniteClient(project=project,\n",
    "                       api_key=api_key,\n",
    "                       client_name=\"dshub\",\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy data\n",
    "\n",
    "This tutorial uses a small dummy data set created below to demonstrate how to do entity matching using Python SDK with Experimental Extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    {\"id\":0, \"name\" : \"KKL_21AA1019CA.PV\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"KKL_13FV1234BU.VW\", \"description\": \"ok\"}\n",
    "]\n",
    "targets = [\n",
    "    {\"id\":0, \"name\" : \"21AA1019CA\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"21AA1019CA\", \"description\": \"wrong\"}, \n",
    "    {\"id\":2, \"name\" : \"13FV1234BU\"},\n",
    "    {\"id\":3, \"name\" : \"13FV1234BU\", \"description\": \"ok\"}\n",
    "]\n",
    "true_matches = [(0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a supervised ml-model and predict for the same data\n",
    "\n",
    "The supervised model calculates one or more similarity measures between match-to and match-from items. Then it uses these calculated similarity measures as features and fits a classification model using the labeled data.\n",
    "\n",
    "Note, before calculating the similarity measures and training a model a set a candidate matches are selected. A pair of match-to and match-from items is considered to be a candidate if they have at least one token in common. Only the candidate match-from, match-to combinations are used in the training.  This is done to reduce computing time - calculating similarity measures for all possible combinations can be extremely heavy (10.000 time series and 30.000 assets -> 300.000.000 combinations). \n",
    "\n",
    "#### When to use a supervised ml-model?\n",
    "A supervised ml-model is applicable when you have a number of labeled data. The more labeled data you have, the better results you might achieve. It is not recommended to apply for a supervised model if you have <500 labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   true_matches = true_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "When `predict` is called without any data, predictions are on the training data.\n",
    "\n",
    "`num_matches` determines the number of matches to return for each `matchFrom` item, default is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint(matches[\"items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For both `matchFrom` items we see that the two matches returned have an equal score. Hence, the model is not able to distinguish between the correct and incorrect match. \n",
    "Also, the scores are quite low. Unsupervised learning makes more sense when the data set is  small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit\n",
    "\n",
    "Refit lets you retrain a model (using the same parameters) with additional labels/true-matches. The new `true_matches` (1,3) are added to the `true_matches`-list from the original model.   \n",
    "\n",
    "To fit a model using only the (1,3) label. A new model must be trained using `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.refit(true_matches = [(1,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint(matches[\"items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In this example the results are the same. The new true-match follows the exact same pattern as the original. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit unsupervised model\n",
    "\n",
    "If there are no `true_matches` included in the `fit` call, an unsupervised model is applied.\n",
    "\n",
    "As for a supervised model candidates are selected and similarity measures between the candidates are calculated. However, instead of training a classification model, the average of the average of the similarity measures are calculated and returned as the score. \n",
    "\n",
    "#### When to use a supervised ml-model?\n",
    "When there are no or few true matches (labeled data), an unsupervised model is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint(matches[\"items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The scores have increased, but the model is still not able to distinguish between the correct and incorrect match. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional key `match_fields` \n",
    "\n",
    "#### When to use the key `match_fields`?\n",
    "By default only name in `sources` and name in `targets` are used to calculate similarity measures. The `match_fields` parameter lets you specify all combinations of fields in `sources` and `targets` that should be used to calculate features.  \n",
    "\n",
    "In this example it looks like also comparing the description field for both `targets` and `sources` will improve the model.\n",
    "\n",
    "Note: Calculating similarity measures can be time consuming. Therefore, we avoid adding `match_fields` combinations which adds little or no information to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = client.entity_matching.fit(sources = sources,\n",
    "                                       targets = targets,\n",
    "                                       match_fields = [(\"name\", \"name\"), (\"description\", \"description\")]\n",
    "                                      )\n",
    "except CogniteAPIError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request results in an error because one of the items in `match_to` is missing description. \n",
    "If the `complete_missing` is set to `True` missing values are replaced by empty strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `ignore_missing_fields`\n",
    "To not get not get an error if some items in sources or targets having missing values add `ignore_missing_fields`=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\"), (\"description\", \"description\")],\n",
    "                                   ignore_missing_fields = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint(matches[\"items\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The model now gives the correct matches a score of 1 and the incorrect matches score 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use different `feature_type`\n",
    "\n",
    "#### When to use the different feature type?\n",
    "By default `feature_type` is set to \"simple\". The  different feature-types are created to improve the accuracy of the model for different types  of  input data. Hence, which feature-type that works best for your model will vary based on what your data look like. The options of feature_type are:\"simple\", \"bigram\", \"frequency-weighted-bigram\", \"bigram-extra-tokenizers\", \"bigram-combo\". This section illustrates the strengths and weaknesses of the different feature-types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to use `feature_type=simple`?\n",
    "Simple is the default feature-type. This feature-type is preferred to use when one string is a substring of the other, and the rest characters are not appeared in the other string. For example \\\"BCDEF\\\" is a substring of \\\"A<u>BCDEF</u>G\\\", and the rest characters \\\"AG\\\" is not appeared in the string \\\"BCDEF\\\". This feature-type is also the fasts option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    {\"id\":0, \"name\" : \"KKL_21AA1019CA.PV\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"KKL_13FV1234BU.VW\", \"description\": \"ok\"}\n",
    "]\n",
    "targets = [\n",
    "    {\"id\":0, \"name\" : \"21AA1019CA\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"21AA1119CA\", \"description\": \"wrong\"}, \n",
    "    {\"id\":2, \"name\" : \"13FV1234BU\"},\n",
    "    {\"id\":3, \"name\" : \"13FV1334BU\", \"description\": \"ok\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\")],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The limitation of simple feature type\n",
    "\n",
    "The data below is the same as what was used in the previous examples, except that there are two new items in targets.  \n",
    "Id 10 and 13 are similar to 0 and 3 respectively, but the first letter combination (\"AA\" and \"FV\") are swapped with the prefix for the match_from items (KKL). \n",
    "\n",
    "We will now see how this leads to difficulties if we use the default `feature_type` (\"simple”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    {\"id\":0, \"name\" : \"KKL_21AA1019CA.PV\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"KKL_13FV1234BU.VW\", \"description\": \"ok\"}\n",
    "]\n",
    "targets = [\n",
    "    {\"id\":0, \"name\" : \"21AA1019CA\", \"description\": \"correct\"}, \n",
    "    {\"id\":10, \"name\" : \"21KKL1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":1, \"name\" : \"21AA1119CA\", \"description\": \"wrong\"}, \n",
    "    {\"id\":2, \"name\" : \"13FV1234BU\"},\n",
    "    {\"id\":3, \"name\" : \"13FV1334BU\", \"description\": \"ok\"},\n",
    "    {\"id\":13, \"name\" : \"13KKL1234BU\", \"description\": \"ok\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\")],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The new `targets`-items have identical scores as the correct matches. \n",
    "This is because when using `feature_type`=\"simple\" only the number of matching tokens are considered. \n",
    "\n",
    "Hence, for `targets`-item with id 0 `21`, `AA`, `1019` and `CA` matches a token in `sources`-item with id 0.\n",
    "For `targets`-item with id 10 `21`, `KKL`, `1019` and `CA` matches a token in `sources`-item with id 0. Thus, the same number of tokens matches. \n",
    "\n",
    "The model does not take into account the `targets`-item with id 0 have more and longer contiguous sequences of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to use `feature_type=bigram`?\n",
    "The \\\"bigram\\\" `feature_type` does account for sequences of tokens. In addition to counting the number of matching tokens it also looks at the number of matching bigrams. That is, the number of matching tokens when two and two adjacent tokens are combined. For example, BCDEF and A<u>B</u>B<u>C</u><u>D</u><u>E</u>1<u>F</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    {\"id\":0, \"name\" : \"KKL_21AA1019CA.PV\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"KKL_13FV1234BU.VW\", \"description\": \"ok\"}\n",
    "]\n",
    "targets = [\n",
    "    {\"id\":0, \"name\" : \"21AA1019CA\", \"description\": \"correct\"}, \n",
    "    {\"id\":10, \"name\" : \"21KKL1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":1, \"name\" : \"21AA1119CA\", \"description\": \"wrong\"}, \n",
    "    {\"id\":2, \"name\" : \"13FV1234BU\"},\n",
    "    {\"id\":3, \"name\" : \"13FV1334BU\", \"description\": \"ok\"},\n",
    "    {\"id\":13, \"name\" : \"13KKL1234BU\", \"description\": \"ok\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\")],\n",
    "                                   feature_type = \"bigram\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to use `feature_type=Frequency-Weighted-Bigram`?\n",
    "Calculates a similarity score based on the sequence of the terms, it also giving higher weights to less commonly occurring tokens. This is helpful when simple feature_type does not return good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    {\"id\":0, \"name\" : \"KKL_21AA1019CA.PV\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"KKL_13FV1234BU.VW\", \"description\": \"ok\"}\n",
    "]\n",
    "targets = [\n",
    "    {\"id\":0, \"name\" : \"21AA1019CA\", \"description\": \"correct\"}, \n",
    "    {\"id\":10, \"name\" : \"21KKL1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":1, \"name\" : \"21AA1119CA\", \"description\": \"wrong\"}, \n",
    "    {\"id\":2, \"name\" : \"13FV1234BU\"},\n",
    "    {\"id\":3, \"name\" : \"13FV1334BU\", \"description\": \"ok\"},\n",
    "    {\"id\":13, \"name\" : \"13KKL1234BU\", \"description\": \"ok\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\")],\n",
    "                                   feature_type = \"frequency-weighted-bigram\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to use `feature_type=Bigram-Extra-Tokenizers`?\n",
    "Similar to bigram, but able to learn that leading zeros and spaces should be ignored in matching. For example ABCDE and 000A<u>B</u>B<u>C</u><u>D</u><u>E</u>1<u>F</u>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    {\"id\":0, \"name\" : \"KKL_21AA1019CA.PV\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"KKL_13FV1234BU.VW\", \"description\": \"ok\"}\n",
    "]\n",
    "targets = [\n",
    "    {\"id\":0, \"name\" : \"000021AA1019CA\", \"description\": \"correct\"}, \n",
    "    {\"id\":10, \"name\" : \"21KKL1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":1, \"name\" : \"21AA1119CA\", \"description\": \"wrong\"}, \n",
    "    {\"id\":2, \"name\" : \"000013FV1234BU\"},\n",
    "    {\"id\":3, \"name\" : \"13FV1334BU\", \"description\": \"ok\"},\n",
    "    {\"id\":13, \"name\" : \"13KKL1234BU\", \"description\": \"ok\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's see the matching results using bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\")],\n",
    "                                   feature_type = \"bigram\"\n",
    ")\n",
    "\n",
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Then let's see how bigram-extra-tokenizer can improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\")],\n",
    "                                   feature_type = \"Bigram-Extra-Tokenizers\"\n",
    ")\n",
    "\n",
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When to use `feature_type=Bigram-Combo`?\n",
    "Calculates all of the above options, relying on the model to determine the appropriate features to use. This is the slowest option and mostly appropriate for a supervised model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\")],\n",
    "                                   feature_type = \"bigram-combo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the score\n",
    "The score above 0.8 indicates that the source and the target are matched with high probability. But for the score below 0.8 and above 0.5 does not indicates the source and the target are matched over 50% probability. Below shows an example that the source and the target does not match at all, but they receive score over 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    {\"id\":0, \"name\" : \"J04_ONSTREAM_HOUR_AVG\", \"description\": \"correct\"}, \n",
    "]\n",
    "targets = [\n",
    "    {\"id\":0, \"name\" : \"87-JB-004-J04\", \"description\": \"correct\"}, \n",
    "]\n",
    "\n",
    "model = client.entity_matching.fit(sources = sources,\n",
    "                                   targets = targets,\n",
    "                                   match_fields = [(\"name\", \"name\")],\n",
    "                                   feature_type = \"bigram\"\n",
    ")\n",
    "job = model.predict(num_matches = 1)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on new data\n",
    "\n",
    "To predict on new (unseen) data, simply add this data in the `predict`-call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    {\"id\":100, \"name\" : \"KKL_44AB45\", \"description\": \"ok\"}\n",
    "]\n",
    "targets = [\n",
    "    {\"id\":100,  \"name\" : \"44AB45\", \"description\": \"ok\"},\n",
    "    {\"id\":101, \"name\" : \"44AB45\", \"description\": \"ok12\"},\n",
    "    {\"id\":102,  \"name\" : \"44AB45\"}\n",
    "]\n",
    "\n",
    "job = model.predict(sources = sources,\n",
    "                    targets = targets,\n",
    "                    num_matches = 3,\n",
    "                    )\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model info\n",
    "\n",
    "If you have a model_id and want to know which parameters you used when training the model, use the `retrieve` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.entity_matching.retrieve(id = model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

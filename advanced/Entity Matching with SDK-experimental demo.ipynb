{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Matching with SDK-experimental demo\n",
    "\n",
    "This notebook uses a small dummy data set to demonstrate how to do entity matching using cognite-sdk-python-experimental.\n",
    "\n",
    "It aims at demonstrating most of the capabilities available, explain when the different parameter combinations are most suitable and explain (in some detail) what happens in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get access to CDF\n",
    "We assume you have some basic knowledge of CDF and the SDK. If not, please follow the 'lab' tutorials first.\n",
    "\n",
    "To do this tutorial you nee have access to a Cognite project / tenant, you can apply for one here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "We need to import some Python modules in order to interact with CDF. We will use the Python SDK with Experimental Extensions, which we below refer to as a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.client.exceptions import CogniteAPIError\n",
    "from cognite.experimental import CogniteClient # version: ~0.22.3\n",
    "from getpass import getpass\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a client\n",
    "\n",
    "To get access to your project, replace \"yourproject\" with your project name in the next cell. \n",
    "\n",
    "When you create the CogniteClient below, getpass will ask for your API key in an extra password field. Simply paste it in and press shift+enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'contextualization'\n",
    "api_key = getpass(\"Please enter API key: \")\n",
    "client = CogniteClient(project=project,\n",
    "                       api_key=api_key,\n",
    "                       client_name=\"dshub\",\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy data\n",
    "\n",
    "This tutorial uses a small dummy data set created below to demonstrate how to do entity matching using Python SDK with Experimental Extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_from = [\n",
    "    {\"id\":0, \"name\" : \"KKL_21AA1019CA.PV\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"KKL_13FV1234BU.VW\", \"description\": \"ok\"}\n",
    "]\n",
    "match_to = [\n",
    "    {\"id\":0, \"name\" : \"21AA1019CA\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"21AA1019CA\", \"description\": \"wrong\"}, \n",
    "    {\"id\":2, \"name\" : \"13FV1234BU\"},\n",
    "    {\"id\":3, \"name\" : \"13FV1234BU\", \"description\": \"ok\"}\n",
    "]\n",
    "true_matches = [(0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a supervised ml-model and predict for the same data\n",
    "\n",
    "The supervised model calculates one or more similarity measures between match-to and match-from items. Then it uses these calculated similarity measures as features and fits a classification model using the labeled data.\n",
    "\n",
    "Note, before calculating the similarity measures and training a model a set a candidate matches are selected. A pair of match-to and match-from items is considered to be a candidate if they have at least one token in common. Only the candidate match-from, match-to combinations are used in the training.  This is done to reduce computing time - calculating similarity measures for all possible combinations can be extremely heavy (10.000 time series and 30.000 assets -> 300.000.000 combinations). \n",
    "\n",
    "#### When to use a supervised ml-model?\n",
    "A supervised ml-model is applicable when you have a number of labeled data. The more labeled data you have, the better results you might achieve. It is not recommended to apply for a supervised model if you have <500 labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(match_from = match_from,\n",
    "                                   match_to = match_to,\n",
    "                                   true_matches = true_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "When `predict` is called without any data, predictions are on the training data.\n",
    "\n",
    "`num_matches` determines the number of matches to return for each `matchFrom` item, default is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint(matches[\"items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For both `matchFrom` items we see that the two matches returned have an equal score. Hence, the model is not able to distinguish between the correct and incorrect match. \n",
    "Also, the scores are quite low. Unsupervised learning makes more sense when the data set is  small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit\n",
    "\n",
    "Refit lets you retrain a model (using the same parameters) with additional labels/true-matches. The new `true_matches` (1,3) are added to the `true_matches`-list from the original model.   \n",
    "\n",
    "To fit a model using only the (1,3) label. A new model must be trained using `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.refit(true_matches = [(1,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint(matches[\"items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In this example the results are the same. The new true-match follows the exact same pattern as the original. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit unsupervised model\n",
    "\n",
    "If there are no `true_matches` included in the `fit` call, an unsupervised model is trained.\n",
    "\n",
    "As for a supervised model candidates are selected and similarity measures between the candidates are calculated. However, instead of training a classification model, the average of the average of the similarity measures are calculated and returned as the score. \n",
    "\n",
    "#### When to use a supervised ml-model?\n",
    "When there are no or few true matches (labeled data), an unsupervised model is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(match_from = match_from,\n",
    "                                      match_to = match_to\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint(matches[\"items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The scores have increased, but the model is still not able to distinguish between the correct and incorrect match. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add additional keys\n",
    "By default only name in `match_from` and name in `match_to` are used to calculate similarity measures. The `keys_from_to` parameter lets you specify all combinations of fields in `match_from` and `match_to` that should be used to calculate features.  \n",
    "\n",
    "In this example it looks like also comparing the description field for both `match_to` and `match_from` will improve the model.\n",
    "\n",
    "Note: Calculating similarity measures can be time consuming. Therefore, we avoid adding `keys_from_to` combinations which adds little or no information to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = client.entity_matching.fit(match_from = match_from,\n",
    "                                       match_to = match_to,\n",
    "                                       match_fields = [(\"name\", \"name\")]\n",
    "                                      )\n",
    "except CogniteAPIError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request results in an error because one of the items in `match_to` is missing description. \n",
    "If the `complete_missing` is set to `True` missing values are replaced by empty strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `ignore_missing_fields`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(match_from = match_from,\n",
    "                                   match_to = match_to,\n",
    "                                   match_fields = [(\"name\", \"name\"), (\"description\", \"description\")],\n",
    "                                   ignore_missing_fields = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint(matches[\"items\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The model now gives the correct matches a score of 1 and the incorrect matches score 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional match_to items\n",
    "\n",
    "The data below is the same as what was used in the previous examples, except that there are two new items in match_to.  \n",
    "Id 10 and 13 are similar to 0 and 3 respectively, but the first letter combination (\"AA\" and \"FV\") are swapped with the prefix for the match_from items (KKL). \n",
    "\n",
    "We will now see how this leads to difficulties if we use the default `feature_type` (\"simpleâ€)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_from = [\n",
    "    {\"id\":0, \"name\" : \"KKL_21AA1019CA.PV\", \"description\": \"correct\"}, \n",
    "    {\"id\":1, \"name\" : \"KKL_13FV1234BU.VW\", \"description\": \"ok\"}\n",
    "]\n",
    "match_to = [\n",
    "    {\"id\":0,  \"name\" : \"21AA1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":10, \"name\" : \"21KKL1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":1,  \"name\" : \"21AA1019CA\", \"description\": \"wrong\"}, \n",
    "    {\"id\":2,  \"name\" : \"13FV1234BU\"},\n",
    "    {\"id\":3,  \"name\" : \"13FV1234BU\", \"description\": \"ok\"},\n",
    "    {\"id\":13, \"name\" : \"13KKL1234BU\", \"description\": \"ok\"}\n",
    "]\n",
    "true_matches = [(0,0), (1,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(match_from = match_from,\n",
    "                                   match_to = match_to,\n",
    "                                   match_fields = [(\"name\", \"name\"), (\"description\", \"description\")],\n",
    "                                   ignore_missing_fields = True,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The new `match_to`-items have identical scores as the correct matches. \n",
    "This is because when using `feature_type`=\"simple\" only the number of matching tokens are considered. \n",
    "\n",
    "Hence, for `match_to`-item with id 0 `21`, `AA`, `1019` and `CA` matches a token in `match-from`-item with id 0.\n",
    "For `match_to`-item with id 10 `21`, `KKL`, `1019` and `CA` matches a token in `match-from`-item with id 0. Thus, the same number of tokens matches. \n",
    "\n",
    "The model does not take into account the `match_to`-item with id 0 have more and longer contiguous sequences of tokens.\n",
    "\n",
    "The \"bigram\" `feature_type` does somewhat account for longer contiguous sequences of tokens. In addition to counting the number of matching tokens it also looks at the number of matching bigrams. That is, the number of matching tokens when two and two adjacent tokens are combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change `feature_type` \n",
    "The options of feature_type are:\t\"simple\", \"bigram\", \"frequency-weighted-bigram\", \"bigram-extra-tokenizers\", \"bigram-combo\".\n",
    "\n",
    "#### Simple\n",
    "Simple is used by default for feature_type. This type is perfered to apply when one string is a substring of the other. For example BCDEF is a substring of A<u>BCDEF</u>G. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram\n",
    "Adds similarity score based on the sequence of the terms. This type is applicable when two strings in the same or very similar sequences. For example, BCDEF and A<u>B</u>B<u>C</u><u>D</u><u>E</u>1<u>F</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(match_from = match_from,\n",
    "                                   match_to = match_to,\n",
    "                                   match_fields = [(\"name\", \"name\"), (\"description\", \"description\")],\n",
    "                                   ignore_missing_fields = True,\n",
    "                                   feature_type = \"bigram\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency-Weighted-Bigram \n",
    "Calculates a similarity score based on the sequence of the terms, giving higher weights to less commonly occurring tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(match_from = match_from,\n",
    "                                   match_to = match_to,\n",
    "                                   match_fields = [(\"name\", \"name\"), (\"description\", \"description\")],\n",
    "                                   ignore_missing_fields = True,\n",
    "                                   feature_type = \"frequency-weighted-bigram\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram-Extra-Tokenizers\n",
    "Similar to bigram, but able to learn that leading zeros and spaces should be ignored in matching. For example ABCDE and 000A<u>B</u>B<u>C</u><u>D</u><u>E</u>1<u>F</u>. Please note that this feature type could give score above 0.5 for two entity strings which are not match at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_from = [\n",
    "    {\"id\":0, \"name\" : \"21AA1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":0, \"name\" : \"J04_ONSTREAM_HOUR_AVG\", \"description\": \"correct\"}\n",
    "]\n",
    "match_to = [\n",
    "    {\"id\":0,  \"name\" : \"0021AA1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":1,  \"name\" : \"000000021AA1019CA\", \"description\": \"correct\"},\n",
    "    {\"id\":1,  \"name\" : \"87-JB-004-J04\", \"description\": \"correct\"}\n",
    "]\n",
    "\n",
    "model = client.entity_matching.fit(match_from = match_from,\n",
    "                                   match_to = match_to,\n",
    "                                   match_fields = [(\"name\", \"name\"), (\"description\", \"description\")],\n",
    "                                   ignore_missing_fields = True,\n",
    "                                   feature_type = \"bigram-extra-tokenizers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram-Combo\n",
    "Calculates all of the above options, relying on the model to determine the appropriate features to use. This is the slowest option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.entity_matching.fit(match_from = match_from,\n",
    "                                   match_to = match_to,\n",
    "                                   match_fields = [(\"name\", \"name\"), (\"description\", \"description\")],\n",
    "                                   ignore_missing_fields = True,\n",
    "                                   feature_type = \"bigram-combo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "job = model.predict(num_matches = 2)\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on new data\n",
    "\n",
    "To predict on new (unseen) data, simply add this data in the `predict`-call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_from = [\n",
    "    {\"id\":100, \"name\" : \"KKL_44AB45\", \"description\": \"ok\"}\n",
    "]\n",
    "match_to = [\n",
    "    {\"id\":100,  \"name\" : \"44AB45\", \"description\": \"ok\"},\n",
    "    {\"id\":101, \"name\" : \"44AB45\", \"description\": \"ok12\"},\n",
    "    {\"id\":102,  \"name\" : \"44AB45\"}\n",
    "]\n",
    "\n",
    "job = model.predict(match_from = match_from,\n",
    "                    match_to = match_to,\n",
    "                    num_matches = 3,\n",
    "                    )\n",
    "matches = job.result\n",
    "pp.pprint((matches[\"items\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model info\n",
    "\n",
    "If you have a model_id and want to know which parameters you used when training the model, use the `retrieve` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.entity_matching.retrieve(id = model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
